# MFCS Full Conformal Prediction with Normal Distribution Sampling

This repository contains the code to run experiments using the Multistep Feedback Covariate Shift (MFCS) Full Conformal Prediction (CP) algorithm. In this modified version, we use a normal distribution for sampling new data points, and the results are visualized using provided plotting scripts.

## How to Run the Code

To run the experiment and visualize the results, follow these steps:

### 1. Running the Experiment: `run_our_experiment.py`

The main script `run_our_experiment.py` is used to execute the MFCS Full CP experiment with normal distribution-based sampling. This script will generate the results and save them as a CSV file.

### 2. Running the Bash Script: `bash_scripts/our_experiment.sh`

The `our_experiment.sh` script is a bash script that allows you to execute the MFCS Full CP experiment from the terminal with predefined parameters. This is a convenient way to run the experiment without manually specifying parameters every time.

#### To run the bash script:
1. Open your terminal.
2. Navigate to the directory containing the `bash_scripts/our_experiment.sh` script.
3. Run the following command:

bash_scripts/our_experiment.sh

### 3. Plotting Results: `MFCS_FullCP_PlotFigures.ipynb`

The `MFCS_FullCP_PlotFigures.ipynb` Jupyter notebook is used to visualize the results from the MFCS Full Conformal Prediction experiment. This notebook takes the output data generated by running the experiments and creates various plots to analyze coverage, width, and other relevant metrics.

#### To use the notebook:
1. Open the `MFCS_FullCP_PlotFigures.ipynb` notebook in Jupyter.
2. Ensure that the result files from the experiment are available in the expected directory.
3. Run the cells in the notebook to generate the plots for the experiment. These plots will display metrics like coverage, width, and fitness for different steps in the experiment.

This notebook provides a clear visual representation of how the experiment performed under different configurations, comparing the effects of different sampling methods.